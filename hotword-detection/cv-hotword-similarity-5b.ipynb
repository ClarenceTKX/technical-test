{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da785602-b5ac-46f3-8668-8739e2976f13",
   "metadata": {},
   "source": [
    "## B. Text Embedding\n",
    "This task includes the use of `instructor-large` for the search of similar phrases to the hotwords detected in 5a. This will provide an updated `similarity` column with boolean values of whether there are similar phrases or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae8d0bb-0440-4803-ae84-b47c3d3a0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f99f7-1468-4818-94ef-a69d3ac18c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "# model_name = \"hkunlp/instructor-large\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555e56f-ca33-46ea-ab36-d2993a2bf2ba",
   "metadata": {},
   "source": [
    "This section is used to extract out sentences with the hotwords for running cosine similarity with `INSTRUCTOR` on the rest of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20d0f3-6227-4f01-b489-a09b3d184bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Users/Clarence/Desktop/GitHub/technical-test/asr-train/updated_v2_cv-valid-dev.csv') \n",
    "\n",
    "#convert text to lowercase first\n",
    "df['generated_text'] = df['generated_text'].str.lower()\n",
    "df['finetuned_text'] = df['finetuned_text'].str.lower()\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "#Define hotwords and their regex patterns\n",
    "hotwords = {\n",
    "    \"be careful\": r\"be\\s*careful\",\n",
    "    \"destroy\": r\"destroy\",\n",
    "    \"stranger\": r\"stranger\"\n",
    "}\n",
    "\n",
    "# Function to check for hotwords in text\n",
    "def contains_hotword(text, patterns):\n",
    "    for pattern in patterns.values():\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Iterate through the DataFrame and store filenames if hotwords are detected\n",
    "hotword_sentences = []\n",
    "for _, row in df.iterrows():\n",
    "    if contains_hotword(row['finetuned_text'], hotwords):\n",
    "        hotword_sentences.append(row['finetuned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88e0fd31-ea13-4112-ac82-223788fec3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be careful whit your prognostications said the stranger', 'i thought that everything i owned would be destroyed', 'the stranger seemed satisfied with the answer', 'i had to test your courage the stranger said', 'i had to test your corrage the stranger said', 'be careful with your proagnostications said the stranger', 'the stranger was speaking of things that very few people knew about', 'the stranger was speaking of things that very few people knew about', 'i had to test your courage the stranger said', 'the stranger seemed satisfied with the answer', 'the stranger was speaking of things that very few people knew about', \"i don't like people to do that because the sheep are afraid of strangers\", \"the stranger withdrew the sword from the boy's forehead and the boy felt immensely relieved\", 'i had to test your courage the stranger said', 'i had to test your courage the stranger said']\n"
     ]
    }
   ],
   "source": [
    "hotword_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca198ba7-29a0-4088-bd4d-97780180963e",
   "metadata": {},
   "source": [
    "## Running Similarity\n",
    "Based on documentation on `INSTRUCTOR` [[1]](https://github.com/xlang-ai/instructor-embedding), cosine similarity is constructed here to calculate for other similar sentences (including the target sentences themselves). As a reference point, the similarity threshold is set at 0.999. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a85d510-c509-4b9f-ab65-f5445272be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate text embeddings\n",
    "def get_embedding(text):\n",
    "    embeddings = model.encode(text)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09dd711a-72af-4d2f-9660-c7a8c0175a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference embedding tensor for comparison of cosine similarity against sentences in DataFrame\n",
    "hotword_embeddings = get_embedding(hotword_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2105fde3-378e-41a0-8b45-39b4cc2966a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing it out\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(hotword_embeddings, hotword_embeddings) #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f88a0065-ad6b-4258-b7e8-401644b30084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999999 , 0.8266499 , 0.87050796, 0.8903919 , 0.8858587 ,\n",
       "        0.9952303 , 0.8990371 , 0.8990371 , 0.8903919 , 0.87050796,\n",
       "        0.8990371 , 0.8255396 , 0.83485675, 0.89039195, 0.89039195],\n",
       "       [0.8266499 , 1.0000002 , 0.80499256, 0.83657837, 0.8354285 ,\n",
       "        0.83064413, 0.8207717 , 0.8207717 , 0.83657837, 0.80499256,\n",
       "        0.8207717 , 0.8044783 , 0.8110869 , 0.8365785 , 0.8365785 ],\n",
       "       [0.87050796, 0.80499256, 1.0000002 , 0.8845076 , 0.8920334 ,\n",
       "        0.8703649 , 0.8823137 , 0.8823137 , 0.8845076 , 1.0000002 ,\n",
       "        0.8823137 , 0.80607855, 0.8875704 , 0.88450754, 0.88450754],\n",
       "       [0.8903919 , 0.83657837, 0.8845076 , 0.99999994, 0.9691083 ,\n",
       "        0.89021873, 0.8917724 , 0.8917724 , 0.99999994, 0.8845076 ,\n",
       "        0.8917724 , 0.8343547 , 0.84707516, 0.9999998 , 0.9999998 ],\n",
       "       [0.8858587 , 0.8354285 , 0.8920334 , 0.9691083 , 1.        ,\n",
       "        0.88466245, 0.8862458 , 0.8862458 , 0.9691083 , 0.8920334 ,\n",
       "        0.8862458 , 0.829512  , 0.843199  , 0.96910834, 0.96910834],\n",
       "       [0.9952303 , 0.83064413, 0.8703649 , 0.89021873, 0.88466245,\n",
       "        0.9999999 , 0.89696515, 0.89696515, 0.89021873, 0.8703649 ,\n",
       "        0.89696515, 0.8198117 , 0.8331835 , 0.89021873, 0.89021873],\n",
       "       [0.8990371 , 0.8207717 , 0.8823137 , 0.8917724 , 0.8862458 ,\n",
       "        0.89696515, 0.9999999 , 0.9999999 , 0.8917724 , 0.8823137 ,\n",
       "        0.9999999 , 0.8298365 , 0.8363998 , 0.8917725 , 0.8917725 ],\n",
       "       [0.8990371 , 0.8207717 , 0.8823137 , 0.8917724 , 0.8862458 ,\n",
       "        0.89696515, 0.9999999 , 0.9999999 , 0.8917724 , 0.8823137 ,\n",
       "        0.9999999 , 0.8298365 , 0.8363998 , 0.8917725 , 0.8917725 ],\n",
       "       [0.8903919 , 0.83657837, 0.8845076 , 0.99999994, 0.9691083 ,\n",
       "        0.89021873, 0.8917724 , 0.8917724 , 0.99999994, 0.8845076 ,\n",
       "        0.8917724 , 0.8343547 , 0.84707516, 0.9999998 , 0.9999998 ],\n",
       "       [0.87050796, 0.80499256, 1.0000002 , 0.8845076 , 0.8920334 ,\n",
       "        0.8703649 , 0.8823137 , 0.8823137 , 0.8845076 , 1.0000002 ,\n",
       "        0.8823137 , 0.80607855, 0.8875704 , 0.88450754, 0.88450754],\n",
       "       [0.8990371 , 0.8207717 , 0.8823137 , 0.8917724 , 0.8862458 ,\n",
       "        0.89696515, 0.9999999 , 0.9999999 , 0.8917724 , 0.8823137 ,\n",
       "        0.9999999 , 0.8298365 , 0.8363998 , 0.8917725 , 0.8917725 ],\n",
       "       [0.8255396 , 0.8044783 , 0.80607855, 0.8343547 , 0.829512  ,\n",
       "        0.8198117 , 0.8298365 , 0.8298365 , 0.8343547 , 0.80607855,\n",
       "        0.8298365 , 0.99999994, 0.7849418 , 0.83435476, 0.83435476],\n",
       "       [0.83485675, 0.8110869 , 0.8875704 , 0.84707516, 0.843199  ,\n",
       "        0.8331835 , 0.8363998 , 0.8363998 , 0.84707516, 0.8875704 ,\n",
       "        0.8363998 , 0.7849418 , 1.0000001 , 0.84707516, 0.84707516],\n",
       "       [0.89039195, 0.8365785 , 0.88450754, 0.9999998 , 0.96910834,\n",
       "        0.89021873, 0.8917725 , 0.8917725 , 0.9999998 , 0.88450754,\n",
       "        0.8917725 , 0.83435476, 0.84707516, 0.9999998 , 0.9999998 ],\n",
       "       [0.89039195, 0.8365785 , 0.88450754, 0.9999998 , 0.96910834,\n",
       "        0.89021873, 0.8917725 , 0.8917725 , 0.9999998 , 0.88450754,\n",
       "        0.8917725 , 0.83435476, 0.84707516, 0.9999998 , 1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b994c2b-4830-4f8a-a0e2-a1a5011705c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np \n",
    "\n",
    "# Function to check similarity\n",
    "def is_similar(text, threshold=0.87): # Assuming 'get_embedding' uses 'model.encode()' and 'hotword_embeddings' is already computed\n",
    "    text_embedding = get_embedding(text).reshape(1, -1)\n",
    "    cos_sim_scores = cosine_similarity(text_embedding, hotword_embeddings)\n",
    "    # print(cos_sim_scores)\n",
    "    \n",
    "    # Check if any similarity score meets the threshold\n",
    "    return np.any(cos_sim_scores >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "97a42ed1-dfee-4d96-b558-f26cb5880b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81524837 0.81018466 0.805854   0.8037375  0.813777   0.81189054\n",
      "  0.8798793  0.8798793  0.8037375  0.805854   0.8798793  0.8150883\n",
      "  0.7821808  0.8037375  0.8037375 ]]\n"
     ]
    }
   ],
   "source": [
    "#trial with second sentence\n",
    "similarity_2 = is_similar(df['finetuned_text'][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8a8016b-6468-4e4b-a12c-efea404f4251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3fb17fa-d825-4523-b7e0-bd5e2d60d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach similarity column to DataFrame\n",
    "df['similarity'] = ''\n",
    "\n",
    "# Calculate similarity for each text in DataFrame\n",
    "df['similarity'] = df['finetuned_text'].apply(lambda x: is_similar(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93c37137-b2af-47e5-8bbe-26db7fb73036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         filename  \\\n",
      "0  cv-valid-dev/sample-000000.mp3   \n",
      "1  cv-valid-dev/sample-000001.mp3   \n",
      "2  cv-valid-dev/sample-000002.mp3   \n",
      "3  cv-valid-dev/sample-000003.mp3   \n",
      "4  cv-valid-dev/sample-000004.mp3   \n",
      "\n",
      "                                                text  up_votes  down_votes  \\\n",
      "0  be careful with your prognostications said the...         1           0   \n",
      "1  then why should they be surprised when they se...         2           0   \n",
      "2  a young arab also loaded down with baggage ent...         2           0   \n",
      "3  i thought that everything i owned would be des...         3           0   \n",
      "4  he moved about invisible but everyone could he...         1           0   \n",
      "\n",
      "        age  gender   accent duration  \\\n",
      "0                                       \n",
      "1                                       \n",
      "2                                       \n",
      "3                                       \n",
      "4  fourties  female  england            \n",
      "\n",
      "                                      generated_text  \\\n",
      "0  be careful with your prognostications said the...   \n",
      "1  then why should they be surprised when they se...   \n",
      "2  a young arab also loaded down with baggage ent...   \n",
      "3  i felt that everything i owned would be destroyed   \n",
      "4  he moved about invisible but every one could h...   \n",
      "\n",
      "                                      finetuned_text  similarity  \n",
      "0  be careful whit your prognostications said the...        True  \n",
      "1  then why should they be surprised when the see...        True  \n",
      "2  a young arab also loaded downward package ente...        True  \n",
      "3  i thought that everything i owned would be des...        True  \n",
      "4  he moved about invisible but everyone could he...        True  \n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b70db12-08eb-4b01-892a-212d3a0d97ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1     False\n",
       "2     False\n",
       "3      True\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13     True\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "Name: similarity, dtype: bool"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['similarity'][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4a743-79f4-4d22-97c6-fc65e22b513d",
   "metadata": {},
   "source": [
    "## Observations\n",
    "Iteration 1 (threshold = 0.8): returned all True with 100 samples (too warm for detecting similarity)\n",
    "Iteration 2 (threshold = 0.999): Mostly False (with True returned on sentences with hotword x hotword cosine similarity)\n",
    "Iteration 3 (threshold = 0.87): returned some sentences with similar embeddings (e.g, entry 15)\n",
    "\n",
    "While the threshold can be manually adjusted, the tensors hold large dimensions of cosine similarity values, weighed against the `INSTRUCTOR` model. For this task, heuristical observations were made in comparison with hotword embeddings cf. comparative hotword-sentence embeddings to determine the threshold for similarity determination.\n",
    "Modelling for `similarity` in more detail should include statistical graphing of both embeddings, and/or summary statistics to better ascertain threshold levels for determining sentences with similar embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0012fe94-181b-4c8a-834f-9b35da1cdf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to CSV\n",
    "df.to_csv('updated_v3_cv-valid-dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfcd71-dcf9-4bb0-9622-e92201fe60d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
